# Цели парсинга логов Ollama

Этот документ описывает, какую информацию мы хотим извлечь из файла с логами (`ollama_log_dump.txt`) для анализа и отладки.

## 1. Оборудование и доступные ресурсы

Необходимо идентифицировать информацию о системных ресурсах, которую Ollama логирует при старте или при загрузке модели.

- **CPU/RAM**: Общий объем системной памяти, доступная память.
  - *Ключевые строки*: `level=INFO source=server.go:105 msg="system memory"`
- **GPU**: Информация об обнаруженных графических процессорах.
  - **Инициализация**: Детали о GPU (ID, имя, драйвер, VRAM).
    - *Ключевые строки*: `level=INFO source=server.go:138 msg=offload`
  - **Доступная VRAM**: Сколько видеопамяти доступно.
    - *Ключевые строки*: `level=INFO source=sched.go:716 msg="new model will fit in available VRAM"`

## 2. Жизненный цикл модели

Нужно отследить полный жизненный цикл каждой модели: от запроса на загрузку до ее выгрузки.

### А. Загрузка модели (Старт)

- **Время начала**: Точная временная метка, когда началась загрузка модели.
- **Имя модели**: Какая именно модель загружается (например, `phi4:latest`).
- **Параметры модели**: Детали, которые логируются при старте (`general.name`, `phi3.block_count` и т.д.).
  - *Ключевые строки*: `llama_model_loader: - kv ...`

### Б. Использование модели

- **Запросы к модели**: Отслеживать все API-вызовы к уже загруженной модели.
- **Время запроса**: Точная временная метка каждого запроса.
- **Источник запроса (IP)**: IP-адрес клиента.
  - *Ключевые строки*: `[GIN] ... GET|POST ...`
- **Endpoint**: Какой API endpoint был вызван (`/api/chat`, `/api/generate`).
- **Статус и задержка**: Код ответа (200, 500) и время выполнения запроса.

### В. Выгрузка модели (Конец)

- **Время окончания**: Точная временная метка, когда модель была выгружена из памяти.
  - *Примечание*: Ollama может не логировать это событие явно. Выгрузка может происходить по таймауту неактивности. Нам нужно будет отслеживать последнее использование модели.
