# Ollama Log Parser

Этот скрипт `log_parser.py` предназначен для анализа логов сервиса Ollama (`ollama.service`) для отладки и мониторинга. Он собирает информацию о запусках сервиса, использовании ресурсов, загрузке моделей и API-запросах, а затем генерирует сводный отчет в формате Markdown.

## Основные возможности

- **Анализ событий запуска**: Собирает и отображает ключевые события, связанные с запуском, остановкой и перезапуском сервиса Ollama.
- **Сессии моделей**: Группирует логи по сессиям, начиная с момента загрузки определенной модели. Для каждой сессии отображается:
    - Имя модели и её SHA256-хеш.
    - Архитектура и требуемый объем видеопамяти (VRAM).
    - Время загрузки модели.
- **Мониторинг ресурсов**: Отслеживает и показывает состояние системных ресурсов (RAM, VRAM) в контексте каждой сессии.
- **Анализ API-запросов**: Парсит лог API-запросов (GIN), связывает их с активной сессией модели и отображает в виде таблицы.
- **Генерация отчета**: Все собранные данные структурируются и сохраняются в файл `log_analysis.md` для удобного просмотра.

## Как использовать

1.  Убедитесь, что у вас установлен Python 3 и необходимые библиотеки (`requests`).
2.  Запустите скрипт из его директории:
    ```bash
    python3 log_parser.py
    ```

Скрипт выполнит следующие действия:
1.  **`dump_startup_log()`**: Найдет в `journalctl` последний запуск сервиса `ollama.service` и сохранит окружающий его контекст в `startup_info.txt`.
2.  **`dump_recent_logs_to_file()`**: Соберет логи сервиса за последние 30 минут и сохранит их в `ollama_log_dump.txt`.
3.  **`analyze_log_dump()`**: Проанализирует созданные файлы логов и сгенерирует отчет `log_analysis.md`.

## Выходные файлы

- **`ollama_log_dump.txt`**: Полный дамп логов `ollama.service` за последние 30 минут.
- **`startup_info.txt`**: Контекстные строки лога, относящиеся к последнему запуску сервиса.
- **`log_analysis.md`**: Итоговый аналитический отчет в формате Markdown.
